services:
    llm-agents-devcontainer:
        image: llm-agents-devcontainer
        container_name: llm-agents-devcontainer
        build:
            context: ..
            dockerfile: .devcontainer/Dockerfile
        volumes:
            - ..:/workspace:cached
            - ../resources/:/resources
        env_file:
            - ../.env
        # This keeps the devcontainer running.
        entrypoint: ["tail", "-f", "/dev/null"]
        networks:
            - llm-agents

    llm-agents-redis:
        image: redis:8.0.3
        container_name: llm-agents-redis
        volumes:
            - $PWD/resources/cache/redis:/data
        networks:
            - llm-agents

    llm-agents-mongo:
        image: mongo:8.0.12
        container_name: llm-agents-mongo
        ports:
            - "27017:27017"
        command: ["mongod", "--wiredTigerCacheSizeGB", "0.25"]
        volumes:
            - $PWD/resources/db/mongo/db:/data/db:z
        deploy:
            resources:
                limits:
                    cpus: "1"
                    memory: 320M
        restart: unless-stopped
        networks:
            - llm-agents

    llm-agents-ollama:
        image: ollama/ollama:0.10.1
        container_name: llm-agents-ollama
        deploy:
            resources:
                reservations:
                    devices:
                        - driver: nvidia
                          count: 1
                          capabilities: [gpu]
        volumes:
            - $PWD/resources/ollama:/root/.ollama
        networks:
            - llm-agents

networks:
    llm-agents:
        name: llm-agents
        driver: bridge
