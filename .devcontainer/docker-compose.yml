services:
    llm-agents-devcontainer:
        image: llm-agents-devcontainer
        container_name: llm-agents-devcontainer
        build:
            context: ..
            dockerfile: .devcontainer/Dockerfile
        volumes:
            - ..:/workspace:cached
            - ../resources/:/resources
        env_file:
            - .env
        # This keeps the devcontainer running.
        entrypoint: ["tail", "-f", "/dev/null"]
        networks:
            - llm-agents

    llm-agents-redis:
        image: redis:8.0.1
        container_name: llm-agents-redis
        volumes:
            - $PWD/resources/cache/redis:/data
        networks:
            - llm-agents

    llm-agents-ollama:
        image: ollama/ollama:0.7.0
        container_name: llm-agents-ollama
        # deploy:
        #     resources:
        #         reservations:
        #             devices:
        #                 - driver: nvidia
        #                   count: 1
        #                   capabilities: [gpu]
        volumes:
            - $PWD/resources/ollama:/root/.ollama
        networks:
            - llm-agents

networks:
    llm-agents:
        name: llm-agents
        driver: bridge
